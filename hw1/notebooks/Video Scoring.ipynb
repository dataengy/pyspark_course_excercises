{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b94b2e0-3796-411b-ad82-1b56e7f89e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://76c09a2dee74:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff9496f750>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "    .config('spark.sql.autoBroadcastJoinThreshold', 0) \\\n",
    "    .config('spark.sql.adaptive.enabled', 'false') \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e9981-940c-40f3-9574-3a13e926e77d",
   "metadata": {},
   "source": [
    "#### Spark UI:\n",
    "- http://127.0.0.1:4040/stages/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a6214ad8-178b-4eac-b47d-e84f7f202d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\tdatasets/US_category_id.json\n",
      "71108\tdatasets/UScomments.csv\n",
      "2916\tdatasets/USvideos.csv\n"
     ]
    }
   ],
   "source": [
    "!du datasets/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c2a19f1-09d4-433b-bb14-495e1f69bf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>K4wEI5zhHB0</td>\n",
       "      <td>cLdxuaxaQwc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>iPhone X — Introducing iPhone X — Apple</td>\n",
       "      <td>My Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_title</th>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>Apple</td>\n",
       "      <td>PewDiePie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...</td>\n",
       "      <td>[none]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>views</th>\n",
       "      <td>4394029</td>\n",
       "      <td>7860119</td>\n",
       "      <td>5845909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>320053</td>\n",
       "      <td>185853</td>\n",
       "      <td>576597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dislikes</th>\n",
       "      <td>5931</td>\n",
       "      <td>26679</td>\n",
       "      <td>39774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_total</th>\n",
       "      <td>46245</td>\n",
       "      <td>0</td>\n",
       "      <td>170708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumbnail_link</th>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>https://i.ytimg.com/vi/K4wEI5zhHB0/default.jpg</td>\n",
       "      <td>https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>13.09</td>\n",
       "      <td>13.09</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                0  \\\n",
       "video_id                                              XpVt6Z1Gjjo   \n",
       "title           1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...   \n",
       "channel_title                                    Logan Paul Vlogs   \n",
       "category_id                                                    24   \n",
       "tags            logan paul vlog|logan paul|logan|paul|olympics...   \n",
       "views                                                     4394029   \n",
       "likes                                                      320053   \n",
       "dislikes                                                     5931   \n",
       "comment_total                                               46245   \n",
       "thumbnail_link     https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg   \n",
       "date                                                        13.09   \n",
       "\n",
       "                                                                1  \\\n",
       "video_id                                              K4wEI5zhHB0   \n",
       "title                     iPhone X — Introducing iPhone X — Apple   \n",
       "channel_title                                               Apple   \n",
       "category_id                                                    28   \n",
       "tags            Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...   \n",
       "views                                                     7860119   \n",
       "likes                                                      185853   \n",
       "dislikes                                                    26679   \n",
       "comment_total                                                   0   \n",
       "thumbnail_link     https://i.ytimg.com/vi/K4wEI5zhHB0/default.jpg   \n",
       "date                                                        13.09   \n",
       "\n",
       "                                                             2  \n",
       "video_id                                           cLdxuaxaQwc  \n",
       "title                                              My Response  \n",
       "channel_title                                        PewDiePie  \n",
       "category_id                                                 22  \n",
       "tags                                                    [none]  \n",
       "views                                                  5845909  \n",
       "likes                                                   576597  \n",
       "dislikes                                                 39774  \n",
       "comment_total                                           170708  \n",
       "thumbnail_link  https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg  \n",
       "date                                                     13.09  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = spark.read.option('header', 'true').option(\"inferSchema\", \"true\").csv('datasets/USvideos.csv')\n",
    "# videos.show(3, False, True)\n",
    "videos.limit(3).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "805005cc-0c92-45e3-ab79-44a348f9c2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Logan Paul it's yo big day ‼️‼️‼️</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>I've been following you from the start of your...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Say hi to Kong and maverick for me</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                       comment_text  likes  \\\n",
       "0  XpVt6Z1Gjjo                  Logan Paul it's yo big day ‼️‼️‼️      4   \n",
       "1  XpVt6Z1Gjjo  I've been following you from the start of your...      3   \n",
       "2  XpVt6Z1Gjjo                 Say hi to Kong and maverick for me      3   \n",
       "\n",
       "   replies  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_schema = StructType([ \\\n",
    "    StructField(\"video_id\", StringType(), True), \\\n",
    "    StructField(\"comment_text\", StringType(), True), \\\n",
    "    StructField(\"likes\", IntegerType(), True), \\\n",
    "    StructField(\"replies\", IntegerType(), True)])\n",
    "comments = spark.read.option('header', 'true').option(\"mode\", \"DROPMALFORMED\").schema(comments_schema).csv('datasets/UScomments.csv')\n",
    "(comments\n",
    " # .where(\"likes < 0\")\n",
    " .limit(3).toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c2c54-c12e-4c72-9208-90335cf00972",
   "metadata": {},
   "source": [
    "1 scored_videos - датасет на USvideos.csv\n",
    " - с добавлением колонки, содержащей скор (показатель качества) видео: ФОРМУЛА должна включать в себя\n",
    "     - просмотры,\n",
    "     - лайки,дизлайки видео,\n",
    "     - лайки и дизлайки к комментариям к видео\n",
    "       \n",
    "2 categories_score - по категориям, в котором поля: \n",
    " - Название категории (не id) -  в US_category_id.json\n",
    " - Медиана показателя score из scored_videos по каждой категории\n",
    "\n",
    "3 popular_tags - по самым популярным тэгам\n",
    "  - название тэга + количество видео с этим тэгом\n",
    "    ! тэги лежат строкой в поле tags\n",
    "      - Scala-функцию для разбиения тегов: \n",
    "        - Но напишите свою UDF-функцию разбиения строки на тэги\n",
    "        - и сравните время работы с её Scala-версией.\n",
    "          - Можно замерять своими силами,\n",
    "            - а можно воспользоваться библиотекой timeit\n",
    "            - функции Spark из пакета pyspark.sq.functions использовать нельзя,\n",
    "              - нужно написать свою функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f0c81cd-82b6-4148-917f-7a45c4b44f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>K4wEI5zhHB0</td>\n",
       "      <td>cLdxuaxaQwc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>iPhone X — Introducing iPhone X — Apple</td>\n",
       "      <td>My Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_title</th>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>Apple</td>\n",
       "      <td>PewDiePie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...</td>\n",
       "      <td>[none]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>views</th>\n",
       "      <td>4394029</td>\n",
       "      <td>7860119</td>\n",
       "      <td>5845909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>320053</td>\n",
       "      <td>185853</td>\n",
       "      <td>576597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dislikes</th>\n",
       "      <td>5931</td>\n",
       "      <td>26679</td>\n",
       "      <td>39774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_total</th>\n",
       "      <td>46245</td>\n",
       "      <td>0</td>\n",
       "      <td>170708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumbnail_link</th>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>https://i.ytimg.com/vi/K4wEI5zhHB0/default.jpg</td>\n",
       "      <td>https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>13.09</td>\n",
       "      <td>13.09</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                0  \\\n",
       "video_id                                              XpVt6Z1Gjjo   \n",
       "title           1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...   \n",
       "channel_title                                    Logan Paul Vlogs   \n",
       "category_id                                                    24   \n",
       "tags            logan paul vlog|logan paul|logan|paul|olympics...   \n",
       "views                                                     4394029   \n",
       "likes                                                      320053   \n",
       "dislikes                                                     5931   \n",
       "comment_total                                               46245   \n",
       "thumbnail_link     https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg   \n",
       "date                                                        13.09   \n",
       "\n",
       "                                                                1  \\\n",
       "video_id                                              K4wEI5zhHB0   \n",
       "title                     iPhone X — Introducing iPhone X — Apple   \n",
       "channel_title                                               Apple   \n",
       "category_id                                                    28   \n",
       "tags            Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...   \n",
       "views                                                     7860119   \n",
       "likes                                                      185853   \n",
       "dislikes                                                    26679   \n",
       "comment_total                                                   0   \n",
       "thumbnail_link     https://i.ytimg.com/vi/K4wEI5zhHB0/default.jpg   \n",
       "date                                                        13.09   \n",
       "\n",
       "                                                             2  \n",
       "video_id                                           cLdxuaxaQwc  \n",
       "title                                              My Response  \n",
       "channel_title                                        PewDiePie  \n",
       "category_id                                                 22  \n",
       "tags                                                    [none]  \n",
       "views                                                  5845909  \n",
       "likes                                                   576597  \n",
       "dislikes                                                 39774  \n",
       "comment_total                                           170708  \n",
       "thumbnail_link  https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg  \n",
       "date                                                     13.09  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.limit(3).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07a8aefa-d965-4318-893d-deea06ef9755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      " |-- comment_total: integer (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- comment_text: string (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- replies: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Logan Paul it's yo big day ‼️‼️‼️</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>I've been following you from the start of your...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Say hi to Kong and maverick for me</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                       comment_text  likes  \\\n",
       "0  XpVt6Z1Gjjo                  Logan Paul it's yo big day ‼️‼️‼️      4   \n",
       "1  XpVt6Z1Gjjo  I've been following you from the start of your...      3   \n",
       "2  XpVt6Z1Gjjo                 Say hi to Kong and maverick for me      3   \n",
       "\n",
       "   replies  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.printSchema()\n",
    "comments.printSchema()\n",
    "comments.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fc0d78b-8c9c-49dc-ab05-b8fa4ddb349d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ColumnOrName'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0mtry_remote_functions\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ColumnOrName\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns the first column that is not null.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. versionadded:: 1.4.0\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. versionchanged:: 3.4.0\u001b[0m\n",
       "\u001b[0;34m        Supports Spark Connect.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    cols : :class:`~pyspark.sql.Column` or str\u001b[0m\n",
       "\u001b[0;34m        list of columns to work on.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    :class:`~pyspark.sql.Column`\u001b[0m\n",
       "\u001b[0;34m        value of the first column that is not null.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], (\"a\", \"b\"))\u001b[0m\n",
       "\u001b[0;34m    >>> cDf.show()\u001b[0m\n",
       "\u001b[0;34m    +----+----+\u001b[0m\n",
       "\u001b[0;34m    |   a|   b|\u001b[0m\n",
       "\u001b[0;34m    +----+----+\u001b[0m\n",
       "\u001b[0;34m    |null|null|\u001b[0m\n",
       "\u001b[0;34m    |   1|null|\u001b[0m\n",
       "\u001b[0;34m    |null|   2|\u001b[0m\n",
       "\u001b[0;34m    +----+----+\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> cDf.select(coalesce(cDf[\"a\"], cDf[\"b\"])).show()\u001b[0m\n",
       "\u001b[0;34m    +--------------+\u001b[0m\n",
       "\u001b[0;34m    |coalesce(a, b)|\u001b[0m\n",
       "\u001b[0;34m    +--------------+\u001b[0m\n",
       "\u001b[0;34m    |          null|\u001b[0m\n",
       "\u001b[0;34m    |             1|\u001b[0m\n",
       "\u001b[0;34m    |             2|\u001b[0m\n",
       "\u001b[0;34m    +--------------+\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> cDf.select('*', coalesce(cDf[\"a\"], lit(0.0))).show()\u001b[0m\n",
       "\u001b[0;34m    +----+----+----------------+\u001b[0m\n",
       "\u001b[0;34m    |   a|   b|coalesce(a, 0.0)|\u001b[0m\n",
       "\u001b[0;34m    +----+----+----------------+\u001b[0m\n",
       "\u001b[0;34m    |null|null|             0.0|\u001b[0m\n",
       "\u001b[0;34m    |   1|null|             1.0|\u001b[0m\n",
       "\u001b[0;34m    |null|   2|             0.0|\u001b[0m\n",
       "\u001b[0;34m    +----+----+----------------+\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m_invoke_function_over_seq_of_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coalesce\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/spark/python/pyspark/sql/functions.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coalesce??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d7fa8c3c-3922-46cc-943e-bc68a8b16048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-----+--------+-----------+------+-------+\n",
      "|video_id   |views|likes|dislikes|category_id|tags  |likes_c|\n",
      "+-----------+-----+-----+--------+-----------+------+-------+\n",
      "|4yCkkOvIkUI|2306 |7    |1       |24         |[none]|5      |\n",
      "|4yCkkOvIkUI|2306 |7    |1       |24         |[none]|3      |\n",
      "|4yCkkOvIkUI|2306 |7    |1       |24         |[none]|6      |\n",
      "+-----------+-----+-----+--------+-----------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 scored_videos - датасет на USvideos.csv\n",
    "#  - с добавлением колонки, содержащей скор (показатель качества) видео:\n",
    "#    - ФОРМУЛА должна включать в себя\n",
    "#      - просмотры,\n",
    "#      - лайки, дизлайки видео,\n",
    "#      - лайки и дизлайки к комментариям к видео\n",
    "from pyspark.sql.functions import *\n",
    "videos_s = (\n",
    "    videos.select('video_id', 'views', 'likes', 'dislikes', 'category_id', 'tags')\n",
    "          .join(comments\n",
    "                .select('video_id', col('likes').alias('likes_c'),  # col('dislikes').alias('dislikes_c')  - не нашёл 🤔\n",
    "                ),\n",
    "                on='video_id', how='left'\n",
    "            )\n",
    "          .select('video_id', 'views', 'likes', 'dislikes', 'category_id', 'tags', coalesce(col('likes_c'), lit(0)).alias('likes_c'))\n",
    ")\n",
    "videos_s.cache().show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6756a39e-a31c-4baa-a621-e2be2bfc4974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+--------+-----------+--------------------------------+-------+------------------+\n",
      "|video_id   |views |likes |dislikes|category_id|tags                            |likes_c|score             |\n",
      "+-----------+------+------+--------+-----------+--------------------------------+-------+------------------+\n",
      "|EUoe7cf0HYw|497846|160690|5323    |10         |Taylor Swift|Gorgeous|reputation|26     |0.3121306588784484|\n",
      "|EUoe7cf0HYw|497846|160690|5323    |10         |Taylor Swift|Gorgeous|reputation|7      |0.3120924944661602|\n",
      "|EUoe7cf0HYw|497846|160690|5323    |10         |Taylor Swift|Gorgeous|reputation|7      |0.3120924944661602|\n",
      "|EUoe7cf0HYw|497846|160690|5323    |10         |Taylor Swift|Gorgeous|reputation|6      |0.3120904858128819|\n",
      "|EUoe7cf0HYw|497846|160690|5323    |10         |Taylor Swift|Gorgeous|reputation|5      |0.3120884771596036|\n",
      "+-----------+------+------+--------+-----------+--------------------------------+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+-------+-----+--------+-----------+-----------------------------------------------------------------------+-------+--------------------+\n",
      "|video_id   |views  |likes|dislikes|category_id|tags                                                                   |likes_c|score               |\n",
      "+-----------+-------+-----+--------+-----------+-----------------------------------------------------------------------+-------+--------------------+\n",
      "|tUPR5-igTVY|1267050|0    |0       |22         |dear hate|charity|las vegas charity|las vegas donation|music city cares|1      |7.892348368256975E-7|\n",
      "|tUPR5-igTVY|1267050|0    |0       |22         |dear hate|charity|las vegas charity|las vegas donation|music city cares|1      |7.892348368256975E-7|\n",
      "|tUPR5-igTVY|1267050|0    |0       |22         |dear hate|charity|las vegas charity|las vegas donation|music city cares|1      |7.892348368256975E-7|\n",
      "|tUPR5-igTVY|1267050|0    |0       |22         |dear hate|charity|las vegas charity|las vegas donation|music city cares|1      |7.892348368256975E-7|\n",
      "|tUPR5-igTVY|1267050|0    |0       |22         |dear hate|charity|las vegas charity|las vegas donation|music city cares|1      |7.892348368256975E-7|\n",
      "+-----------+-------+-----+--------+-----------+-----------------------------------------------------------------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2945294"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) score = (likes - dislikes + likes-comments) / views \n",
    "scored_videos = videos_s.withColumn('score', (col('likes') - col('dislikes') + col('likes_c')) / col('views'))\n",
    "scored_videos.orderBy(desc('score')).cache().show(5, False)\n",
    "scored_videos.where('score > 0').orderBy(asc('score')).cache().show(5, False)\n",
    "scored_videos.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3b9adbfc-da4e-437b-af20-c58bc41e2a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"kind\": \"youtube#videoCategoryListResponse\",\n",
      " \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/S730Ilt-Fi-emsQJvJAAShlR6hM\\\"\",\n",
      " \"items\": [\n",
      "  {\n",
      "   \"kind\": \"youtube#videoCategory\",\n",
      "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/Xy1mB4_yLrHy_BmKmPBggty2mZQ\\\"\",\n",
      "   \"id\": \"1\",\n",
      "   \"snippet\": {\n",
      "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
      "    \"title\": \"Film & Animation\",\n",
      "    \"assignable\": true\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"kind\": \"youtube#videoCategory\",\n",
      "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/UZ1oLIIz2dxIhO45ZTFR3a3NyTA\\\"\",\n",
      "   \"id\": \"2\",\n",
      "   \"snippet\": {\n",
      "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
      "    \"title\": \"Autos & Vehicles\",\n",
      "    \"assignable\": true\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Research file with categories:..\n",
    "!head -n 22 datasets/US_category_id.json\n",
    "!echo ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7856beca-f00b-4259-af95-9035e5a21cbc",
   "metadata": {},
   "source": [
    "# https://chat.openai.com/c/fac3b2e7-81c4-4ef5-9cdd-120a459b0fcf\n",
    "how to exctract to spark dataframe with 2 cols:\n",
    "- category_id – from path: \"items\".\"id\" where \"kind\" = \"youtube#videoCategory\"\n",
    "- category_name – from path: \"items\".\"snippet\".\"title\" for category_id\n",
    "\n",
    "from this file:\n",
    "{ \"kind\": \"youtube#videoCategoryListResponse\",\n",
    " \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/S730Ilt-Fi-emsQJvJAAShlR6hM\\\"\",.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "afda89ee-d4cd-43a4-a5d2-129d8624f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|category_id|category_name   |\n",
      "+-----------+----------------+\n",
      "|1          |Film & Animation|\n",
      "|2          |Autos & Vehicles|\n",
      "|10         |Music           |\n",
      "|15         |Pets & Animals  |\n",
      "|17         |Sports          |\n",
      "+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) read categories from json\n",
    "df = spark.read.option(\"multiline\", \"true\").json(\"datasets/US_category_id.json\")\n",
    "\n",
    "df_exploded = df.select(explode(df.items).alias(\"item\"))\n",
    "\n",
    "categories_df = df_exploded.select(\n",
    "    df_exploded[\"item.id\"].alias(\"category_id\"),\n",
    "    df_exploded[\"item.snippet.title\"].alias(\"category_name\")\n",
    ")\n",
    "\n",
    "categories_df = categories_df.filter(df_exploded[\"item.kind\"] == \"youtube#videoCategory\")\n",
    "\n",
    "categories_df.cache().show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c33507ae-2c75-47b5-a84d-a94e1214eff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+\n",
      "|category_name        |median_score        |\n",
      "+---------------------+--------------------+\n",
      "|Shows                |0.012471243491948178|\n",
      "|Education            |0.03368260385297636 |\n",
      "|Gaming               |0.0178513790118479  |\n",
      "|Entertainment        |0.024058260052228886|\n",
      "|Travel & Events      |0.02688961421740934 |\n",
      "|Science & Technology |0.02789074214986546 |\n",
      "|Sports               |0.010208639060805207|\n",
      "|Howto & Style        |0.048267083261007926|\n",
      "|Nonprofits & Activism|0.00800941219059686 |\n",
      "|Film & Animation     |0.022790679555816682|\n",
      "|People & Blogs       |0.03503300560376566 |\n",
      "+---------------------+--------------------+\n",
      "only showing top 11 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) categories_score - по категориям, в котором поля: \n",
    "#  - Название категории (не id) -  в US_category_id.json\n",
    "#  - Медиана показателя score из scored_videos по каждой категории\n",
    "\n",
    "# Join scored_videos and categories_df on category_id\n",
    "##videos_with_categories = scored_videos.join(categories_df, scored_videos.category_id == categories_df.category_id)\n",
    "videos_with_categories = scored_videos.join(categories_df, on='category_id', how='left')\n",
    "\n",
    "# Compute median score\n",
    "median_scores = videos_with_categories.groupby(\"category_name\").agg(\n",
    "    expr('percentile_approx(score, 0.5)').alias('median_score')\n",
    ")\n",
    "\n",
    "median_scores.cache().show(11, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aa278208-36a4-446b-b361-2dc6eb2a8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+-----+--------+--------------------------------------------+-------+--------------------+--------------------+\n",
      "|category_id|   video_id|views|likes|dislikes|                                        tags|likes_c|               score|       category_name|\n",
      "+-----------+-----------+-----+-----+--------+--------------------------------------------+-------+--------------------+--------------------+\n",
      "|         28|CAQ2wWVlOuc|25541|  510|      94|Tech Insider|TI|Tech|Science|Innovation|D...|    278| 0.02717199796405779|Science & Technology|\n",
      "|         28|CAQ2wWVlOuc|25541|  510|      94|Tech Insider|TI|Tech|Science|Innovation|D...|    144|0.021925531498375162|Science & Technology|\n",
      "|         28|CAQ2wWVlOuc|25541|  510|      94|Tech Insider|TI|Tech|Science|Innovation|D...|     83| 0.01953721467444501|Science & Technology|\n",
      "|         28|CAQ2wWVlOuc|25541|  510|      94|Tech Insider|TI|Tech|Science|Innovation|D...|    133|0.021494851415371365|Science & Technology|\n",
      "|         28|CAQ2wWVlOuc|25541|  510|      94|Tech Insider|TI|Tech|Science|Innovation|D...|     54|0.018401785364707726|Science & Technology|\n",
      "+-----------+-----------+-----+-----+--------+--------------------------------------------+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "videos_df = videos_with_categories\n",
    "videos_df.show(5, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d19cada4-f924-43f9-b0b6-0f81082cbba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- likes_c: integer (nullable = false)\n",
      " |-- score: double (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql('drop table scored_videos')\n",
    "videos_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4b287dc2-ae97-4728-ae6f-b053409d0b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+\n",
      "|category_id|   video_id|views|likes|dislikes|  tags|likes_c|                score|category_name|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      5| 0.004770164787510842|Entertainment|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      3|0.0039028620988725065|Entertainment|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      6| 0.005203816131830009|Entertainment|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0|0.0026019080659150044|Entertainment|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0|0.0026019080659150044|Entertainment|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2945294, None)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# videos_df.write.saveAsTable('videos', partitionBy='category_name') #, mode='overwrite')\n",
    "videos_df = spark.table('videos')\n",
    "videos_df.cache().count(), \\\n",
    "videos_df.show(5, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd865e72-487b-4a4c-bbc6-482762e014f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) popular_tags - по самым популярным тэгам\n",
    "  # - название тэга + количество видео с этим тэгом\n",
    "  #   ! тэги лежат строкой в поле tags\n",
    "  #     - Scala-функцию для разбиения тегов: \n",
    "  #       - Но напишите свою UDF-функцию разбиения строки на тэги\n",
    "  #       - и сравните время работы с её Scala-версией.\n",
    "  #         - Можно замерять своими силами,\n",
    "  #           - а можно воспользоваться библиотекой timeit\n",
    "  #           - функции Spark из пакета pyspark.sq.functions использовать нельзя,\n",
    "  #             - нужно написать свою функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e0dbf9ce-763a-48e9-86ff-869bc9c8a2f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkContext' object has no attribute 'addJar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddJar\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuper_udf_lib.jar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'addJar'"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.addJar(\"super_udf_lib.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14206267-719e-4147-b810-ead37c3fd8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://76c09a2dee74:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff994b1f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `videos` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.;\n'UnresolvedRelation [videos], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mmaster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.sql.autoBroadcastJoinThreshold\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \\\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.sql.adaptive.enabled\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.jars\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuper_udf_lib.jar\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m     11\u001b[0m display(spark)\n\u001b[0;32m---> 12\u001b[0m videos \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1476\u001b[0m, in \u001b[0;36mSparkSession.table\u001b[0;34m(self, tableName)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtable\u001b[39m(\u001b[38;5;28mself\u001b[39m, tableName: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the specified table as a :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[1;32m   1448\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;124;03m    +---+\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtableName\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `videos` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.;\n'UnresolvedRelation [videos], [], false\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "# spark.stop(); del spark\n",
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "    .config('spark.sql.autoBroadcastJoinThreshold', 0) \\\n",
    "    .config('spark.sql.adaptive.enabled', 'false') \\\n",
    "    .config(\"spark.jars\", \"super_udf_lib.jar\") \\\n",
    "    .getOrCreate()\n",
    "display(spark)\n",
    "videos = spark.table('videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa320615-dd73-4a22-8a0b-8ab98690afaf",
   "metadata": {},
   "source": [
    "#### Spark UI:\n",
    "- http://127.0.0.1:4040/stages/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5503675d-ab52-4b59-838a-801ccebca2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This system has been minimized by removing packages and content that are\n",
      "not required on a system that users do not log into.\n",
      "\n",
      "To restore this content, including manpages, you can run the 'unminimize'\n",
      "command. You will still need to ensure the 'man-db' package is installed.\n"
     ]
    }
   ],
   "source": [
    "!man apt\n",
    "# -install scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5550b41e-8255-469e-81ca-f23e87fb2552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function posix.system(command)>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os;os.system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4f695937-09f0-4adc-87e0-cdb86cd515d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.7\" 2023-04-18\n",
      "OpenJDK Runtime Environment (build 17.0.7+7-Ubuntu-0ubuntu122.04.2)\n",
      "OpenJDK 64-Bit Server VM (build 17.0.7+7-Ubuntu-0ubuntu122.04.2, mixed mode, sharing)\n",
      "/bin/bash: line 1: scala: command not found\n"
     ]
    }
   ],
   "source": [
    "!java -version\n",
    "!scala --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0db31e39-2c5c-4876-b1a3-c348a63faaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/java\n"
     ]
    }
   ],
   "source": [
    "!which java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "177dfcc8-6961-46df-8af2-0bbbee96adcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin\n",
      "/usr/bin/java:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $PATH\n",
    "export PATH=/usr/bin/java:$PATH\n",
    "echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "887ab3aa-4d90-42a5-ac08-aad8d34cc6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super_udf_lib.jar\n",
      "/bin/bash: line 1: jar: command not found\n"
     ]
    }
   ],
   "source": [
    "!ls super*\n",
    "!jar tf super_udf_lib.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0d4b50bc-555f-4bf4-98a4-a7aea85fbc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt install jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8780bcc7-2a68-4a47-b534-627dcfaf4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "35f14a84-5e75-4a2d-9464-8ca4c0324f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Can not load class com.example.super_udf_lib.CustomUDFs.splitTagsUDF, please make sure it is on the classpath.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrayType, StringType\n\u001b[0;32m----> 3\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregisterJavaFunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplitTags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcom.example.super_udf_lib.CustomUDFs.splitTagsUDF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# \"super_udf_lib.CustomUDFs.splitTagsUDF\",\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mArrayType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStringType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/udf.py:660\u001b[0m, in \u001b[0;36mUDFRegistration.registerJavaFunction\u001b[0;34m(self, name, javaClassName, returnType)\u001b[0m\n\u001b[1;32m    658\u001b[0m         returnType \u001b[38;5;241m=\u001b[39m _parse_datatype_string(returnType)\n\u001b[1;32m    659\u001b[0m     jdt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39mparseDataType(returnType\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m--> 660\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mudf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregisterJava\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjavaClassName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjdt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Can not load class com.example.super_udf_lib.CustomUDFs.splitTagsUDF, please make sure it is on the classpath."
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "spark.udf.registerJavaFunction(\n",
    "    \"splitTags\", \n",
    "    \"com.example.super_udf_lib.CustomUDFs.splitTagsUDF\",\n",
    "    # \"super_udf_lib.CustomUDFs.splitTagsUDF\",\n",
    "    ArrayType(StringType())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a0b311-48a4-4c66-ba9a-6dbe96c4ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+\n",
      "|category_id|   video_id|views|likes|dislikes|  tags|likes_c|                score|category_name|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      5| 0.004770164787510842|Entertainment|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      3|0.0039028620988725065|Entertainment|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      6| 0.005203816131830009|Entertainment|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0|0.0026019080659150044|Entertainment|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0|0.0026019080659150044|Entertainment|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_videos_df():\n",
    "    videos_df = spark.read.parquet('spark-warehouse/videos')\n",
    "    videos_df.cache().count(), \\\n",
    "    videos_df.show(5, 55)\n",
    "    return videos_df\n",
    "\n",
    "videos = get_videos_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e73e8729-1223-47c4-a279-37c88aa34bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_ROUTINE] Cannot resolve function `splitTags` on search path [`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`].; line 2 pos 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m scored_videos\u001b[38;5;241m.\u001b[39mregisterTempTable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscored_videos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m    select splitTags(tags) as tags\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m      from scored_videos\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m11\u001b[39m)\u001b[38;5;241m.\u001b[39mtoPandas()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     litArgs \u001b[38;5;241m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_ROUTINE] Cannot resolve function `splitTags` on search path [`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`].; line 2 pos 11"
     ]
    }
   ],
   "source": [
    "scored_videos.registerTempTable('scored_videos')\n",
    "df = spark.sql(f\"\"\"\n",
    "    select splitTags(tags) as tags\n",
    "      from scored_videos\n",
    "\"\"\")\n",
    "df.cache()\n",
    "df.limit(11).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e42cca98-a64b-4de4-ad90-bc24beccfc5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1195.showString.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3382)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:284)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:323)\n\tat jdk.internal.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[191], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideos_df\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m(): videos_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideos_df\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvideos_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m55\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:912\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    905\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    906\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m         },\n\u001b[1;32m    910\u001b[0m     )\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1195.showString.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3382)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:284)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:323)\n\tat jdk.internal.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n"
     ]
    }
   ],
   "source": [
    "if 'videos_df' not in globals(): videos_df = spark.table('videos_df')\n",
    "videos_df.show(5, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfac461-50b0-4e6d-b95e-9bbdcdc970f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Define a Python function\n",
    "def split_tags(tags_str): return tags_str.split('|')\n",
    "\n",
    "# Create a UDF from the Python function\n",
    "split_tags_udf = udf(split_tags)\n",
    "\n",
    "# Now you can use this UDF in your DataFrame transformations\n",
    "videos = videos.withColumn('tags_array', split_tags_udf(videos['tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f62878-13c5-4176-b598-fdaa876885e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- likes_c: integer (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      " |-- tags_array: string (nullable = true)\n",
      "\n",
      "+-----------+-----------+-----+-----+--------+---------------------------------+-------+--------------------+-------------+---------------------------------+\n",
      "|category_id|   video_id|views|likes|dislikes|                             tags|likes_c|               score|category_name|                       tags_array|\n",
      "+-----------+-----------+-----+-----+--------+---------------------------------+-------+--------------------+-------------+---------------------------------+\n",
      "|         24|eHq6ZA6uKOg|37400|  362|     120|American Broadcasting Company|...|     42|0.007593582887700534|Entertainment|[American Broadcasting Company...|\n",
      "|         24|eHq6ZA6uKOg|37400|  362|     120|American Broadcasting Company|...|      9|0.006711229946524064|Entertainment|[American Broadcasting Company...|\n",
      "|         24|eHq6ZA6uKOg|37400|  362|     120|American Broadcasting Company|...|     37|0.007459893048128342|Entertainment|[American Broadcasting Company...|\n",
      "|         24|eHq6ZA6uKOg|37400|  362|     120|American Broadcasting Company|...|     12|0.006791443850267379|Entertainment|[American Broadcasting Company...|\n",
      "|         24|eHq6ZA6uKOg|37400|  362|     120|American Broadcasting Company|...|      7|0.006657754010695187|Entertainment|[American Broadcasting Company...|\n",
      "+-----------+-----------+-----+-----+--------+---------------------------------+-------+--------------------+-------------+---------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "videos.printSchema()\n",
    "videos.where(f\"tags is not null and tags != '[none]'\").show(5, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c805ace0-2994-4422-acca-c81a1995ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+----------+\n",
      "|category_id|   video_id|views|likes|dislikes|  tags|likes_c|                score|category_name|tags_array|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+----------+\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      5| 0.004770164787510842|Entertainment|  [[none]]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      3|0.0039028620988725065|Entertainment|  [[none]]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      6| 0.005203816131830009|Entertainment|  [[none]]|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----------+-----+\n",
      "|        tag|count|\n",
      "+-----------+-----+\n",
      "|ABC Network|  710|\n",
      "|film review| 5100|\n",
      "|     Heaven| 6700|\n",
      "+-----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, explode\n",
    "from pyspark.sql import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "@pandas_udf('array<string>', PandasUDFType.SCALAR)\n",
    "def split_tags(tags_series: pd.Series) -> pd.Series: return tags_series.str.split('|')\n",
    "\n",
    "def add_tags_array(df: DataFrame, tags_col: str) -> DataFrame: return df.withColumn('tags_array', split_tags(df[tags_col]))\n",
    "\n",
    "# A function to count the number of videos for each tag\n",
    "def count_videos_per_tag(df: DataFrame, tags_array_col: str) -> DataFrame: return (\n",
    "    df.select(\n",
    "        explode(\n",
    "                df[tags_array_col]\n",
    "                   ).alias('tag')\n",
    "     ).groupBy('tag').count()\n",
    ")\n",
    "\n",
    "# Load your DataFrame here\n",
    "# videos = spark.read...\n",
    "\n",
    "# Example data\n",
    "# video_id | title | tags\n",
    "# 1        | video1| tag1|tag2|tag3\n",
    "# 2        | video2| tag1|tag3\n",
    "# 3        | video3| tag2|tag3|tag4\n",
    "\n",
    "videos = add_tags_array(videos, 'tags')\n",
    "videos.show(3, 33)\n",
    "\n",
    "\n",
    "popular_tags = count_videos_per_tag(videos, 'tags_array')\n",
    "\n",
    "# popular_tags will be:\n",
    "# tag  | count\n",
    "# tag1 | 2\n",
    "# tag2 | 2\n",
    "# tag3 | 3\n",
    "# tag4 | 1\n",
    "popular_tags.show(3, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83f0ce47-86e7-4973-b75e-601a0b9f6033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+----------+\n",
      "|category_id|   video_id|views|likes|dislikes|  tags|likes_c|                score|category_name|tags_array|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+----------+\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      5| 0.004770164787510842|Entertainment|  [[none]]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      3|0.0039028620988725065|Entertainment|  [[none]]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      6| 0.005203816131830009|Entertainment|  [[none]]|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+---------------------+-------------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----------+-----------+-----+-----+--------+------+-------+----------------------+-------------+----------+------+\n",
      "|category_id|   video_id|views|likes|dislikes|  tags|likes_c|                 score|category_name|tags_array|   tag|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+----------------------+-------------+----------+------+\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      5|  0.004770164787510842|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      3| 0.0039028620988725065|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      6|  0.005203816131830009|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      2|  0.003469210754553339|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      2|  0.003469210754553339|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      3| 0.0039028620988725065|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      6|  0.005203816131830009|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      5|  0.004770164787510842|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      2|  0.003469210754553339|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      0| 0.0026019080659150044|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 2306|    7|       1|[none]|      2|  0.003469210754553339|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      5|  6.076564715414219E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      3| 2.0255215718047398E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      6|  8.102086287218959E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      0|-4.0510431436094796E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      0|-4.0510431436094796E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      0|-4.0510431436094796E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      2|                   0.0|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      0|-4.0510431436094796E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      2|                   0.0|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      3| 2.0255215718047398E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      6|  8.102086287218959E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      0|-4.0510431436094796E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      0|-4.0510431436094796E-4|Entertainment|  [[none]]|[none]|\n",
      "|         24|4yCkkOvIkUI| 4937|   19|      21|[none]|      5|  6.076564715414219E-4|Entertainment|  [[none]]|[none]|\n",
      "+-----------+-----------+-----+-----+--------+------+-------+----------------------+-------------+----------+------+\n",
      "only showing top 33 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = videos\n",
    "df = df.withColumn('tags_array', split_tags(df['tags']))\n",
    "df.cache().show(3, 33)\n",
    "df = df.select('*',\n",
    "            explode(\n",
    "                df['tags_array']\n",
    "                   ).alias('tag')\n",
    "      )\n",
    "df.show(33, 33)\n",
    "# df = df.groupBy('tag').count()\n",
    "# df = df.orderBy(desc('count'))\n",
    "# df.cache().show(33, 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2add2e1-0f76-4c7c-ad2f-78a54b114403",
   "metadata": {},
   "source": [
    "#### 4) И личная просьба от Марка: он любит котов (а кто не их не любит!) и хочет найти самые интересные комментарии (топ-5) к видео про котов. “Видео про котов” - видео, у которого есть тэг “cat”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ce0457-da64-49fd-b21a-2cd1792cf56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|                tag|count|\n",
      "+-------------------+-----+\n",
      "|          education|40916|\n",
      "|                cat|19505|\n",
      "|          cute cats|16100|\n",
      "|               cats|14301|\n",
      "|          funny cat|12500|\n",
      "|              catch|12319|\n",
      "|        educational|11620|\n",
      "|          cat fails| 8700|\n",
      "|        simons cats| 8700|\n",
      "|      simon the cat| 8700|\n",
      "|         simons cat| 8700|\n",
      "|          simonscat| 8700|\n",
      "|      animated cats| 8700|\n",
      "|black and white cat| 8700|\n",
      "|        simon's cat| 8700|\n",
      "|         cat lovers| 8700|\n",
      "|         funny cats| 8700|\n",
      "|      TED Education| 7885|\n",
      "|        application| 7300|\n",
      "|         cat makeup| 7000|\n",
      "|     cat eye makeup| 7000|\n",
      "|      cat-headlines| 5116|\n",
      "|   every cat at 3am| 4900|\n",
      "|       cat freakout| 4900|\n",
      "|    gus johnson cat| 4900|\n",
      "|   cats compilation| 4900|\n",
      "|          cat prank| 4900|\n",
      "|         crazy cats| 4900|\n",
      "|         cat sketch| 4900|\n",
      "|            gus cat| 4900|\n",
      "|           cat meme| 4900|\n",
      "|        complicated| 4756|\n",
      "|          spidercat| 3600|\n",
      "+-------------------+-----+\n",
      "only showing top 33 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(f\"tag like '%cat%'\").show(33, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b15ca6e-e6c6-41bc-8115-f7b1830e7bda",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `tag` cannot be resolved. Did you mean one of the following? [`tags`, `likes`, `score`, `views`, `likes_c`].; line 1 pos 0;\n'Filter 'tag LIKE %cat%\n+- Project [category_id#0, video_id#1, views#2, likes#3, dislikes#4, tags#5, likes_c#6, score#7, category_name#8, split_tags(tags#5)#1901 AS tags_array#1902]\n   +- Project [category_id#0, video_id#1, views#2, likes#3, dislikes#4, tags#5, likes_c#6, score#7, category_name#8, split_tags(tags#5)#1643 AS tags_array#1644]\n      +- Project [category_id#0, video_id#1, views#2, likes#3, dislikes#4, tags#5, likes_c#6, score#7, category_name#8, split_tags(tags#5)#520 AS tags_array#521]\n         +- Relation [category_id#0,video_id#1,views#2,likes#3,dislikes#4,tags#5,likes_c#6,score#7,category_name#8] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m videos\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtag like \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%cat%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m33\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:3136\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Filters rows using the given condition.\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \n\u001b[1;32m   3082\u001b[0m \u001b[38;5;124;03m:func:`where` is an alias for :func:`filter`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3133\u001b[0m \u001b[38;5;124;03m+---+-----+\u001b[39;00m\n\u001b[1;32m   3134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(condition, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 3136\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(condition, Column):\n\u001b[1;32m   3138\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mfilter(condition\u001b[38;5;241m.\u001b[39m_jc)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `tag` cannot be resolved. Did you mean one of the following? [`tags`, `likes`, `score`, `views`, `likes_c`].; line 1 pos 0;\n'Filter 'tag LIKE %cat%\n+- Project [category_id#0, video_id#1, views#2, likes#3, dislikes#4, tags#5, likes_c#6, score#7, category_name#8, split_tags(tags#5)#1901 AS tags_array#1902]\n   +- Project [category_id#0, video_id#1, views#2, likes#3, dislikes#4, tags#5, likes_c#6, score#7, category_name#8, split_tags(tags#5)#1643 AS tags_array#1644]\n      +- Project [category_id#0, video_id#1, views#2, likes#3, dislikes#4, tags#5, likes_c#6, score#7, category_name#8, split_tags(tags#5)#520 AS tags_array#521]\n         +- Relation [category_id#0,video_id#1,views#2,likes#3,dislikes#4,tags#5,likes_c#6,score#7,category_name#8] parquet\n"
     ]
    }
   ],
   "source": [
    "df = videos\n",
    "df = df.cache().where(f\"tag like '%cat%'\")\n",
    "df.show(33, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb2394-770c-4d6f-91a2-d2532acd7f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
